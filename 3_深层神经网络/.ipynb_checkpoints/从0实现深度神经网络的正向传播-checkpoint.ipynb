{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4587b22",
   "metadata": {},
   "source": [
    "# 深度神经网络的正向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe07df3",
   "metadata": {},
   "source": [
    "我们了解从左向右的过程是神经网络的正向传播(也叫做前向传播，或者向前传播)。还记得我们的架构图吗? 在过去的课程中我们所学习的内容都是在torch.nn这个模块下，现在我们就使用封装好的torch.nn模块来实现一个完整、多层的神经网络的正向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0855e7",
   "metadata": {},
   "source": [
    "假设我们有500条数据，20个特征，标签为3分类。我们现在要实现一个三层神经网络，这个神经网络的架构如下: 第一层有13个神经元，第二层有8个神经元，第三层是输出层。其中，第一层的激活函数是relu，第二层是sigmoid。我们要如何实现它呢?来看代码:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9b14c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89e977f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定数据\n",
    "torch.random.manual_seed(420)\n",
    "X = torch.rand((500,20),dtype = torch.float32)\n",
    "y = torch.randint(low=0,high=3,size=(500,1),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5694cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 继承神经网络里面nn.Module的架构\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,in_features=10,out_features=2):\n",
    "        '''\n",
    "        in_features:  输入该神经网络的特征数目(输入层上的神经元的数目)\n",
    "        out_features: 神经网络的输出的数目 (输出层上的神经元的数目)\n",
    "        '''\n",
    "        super().__init__() \n",
    "        self.linear1 = nn.Linear(in_features,13,bias=True)\n",
    "        self.linear2 = nn.Linear(13,8,bias=True)\n",
    "        self.output = nn.Linear(8,out_features,bias=True)\n",
    "    # 定义神经网络向前传播函数\n",
    "    def forward(self,x):\n",
    "        z1 = self.linear1(x)\n",
    "        sigma1 = torch.relu(z1)\n",
    "        z2 = self.linear2(sigma1)\n",
    "        sigma2 = torch.sigmoid(z2)\n",
    "        z3 = self.output(sigma2)\n",
    "        sigma3 = torch.softmax(z3,dim = 1)\n",
    "        return sigma3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19bb84a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = X.shape[1]\n",
    "output_ = len(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad2664b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化神经网络\n",
    "torch.random.manual_seed(420)\n",
    "net = Model(in_features=input_,out_features=output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "391e2e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4140, 0.3496, 0.2365],\n",
       "        [0.4210, 0.3454, 0.2336],\n",
       "        [0.4011, 0.3635, 0.2355],\n",
       "        ...,\n",
       "        [0.4196, 0.3452, 0.2352],\n",
       "        [0.4153, 0.3455, 0.2392],\n",
       "        [0.4153, 0.3442, 0.2405]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 向前传播\n",
    "net.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04860533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6076d773",
   "metadata": {},
   "source": [
    "线性层上生成的权重矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a34532d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 20])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6124c318",
   "metadata": {},
   "source": [
    "X(500,20) -> X(20,500)<br>\n",
    "w * X = w(13,20) * (20,500) -> (13,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "692872b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 13])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear2.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5e1f42",
   "metadata": {},
   "source": [
    "w * X = w(8,13) * (13,500) -> (8,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c7a2122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.output.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba1301e",
   "metadata": {},
   "source": [
    "w * X = w(3,8) * (8,500) -> (3,500) -> (500,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5405d1dd",
   "metadata": {},
   "source": [
    "线性层上生成的偏置矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7df8156e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eef84970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear2.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "996c3415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.output.bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e53802",
   "metadata": {},
   "source": [
    "# Module中经典的属性和方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29836c27",
   "metadata": {},
   "source": [
    "## 属性的继承"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "353a3b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型是否用于训练\n",
    "net.training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e1ac15",
   "metadata": {},
   "source": [
    "## 方法的继承"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66c4f2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (linear1): Linear(in_features=20, out_features=13, bias=True)\n",
       "  (linear2): Linear(in_features=13, out_features=8, bias=True)\n",
       "  (output): Linear(in_features=8, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将整个网络转移到GPU上来运行\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e65279b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (linear1): Linear(in_features=20, out_features=13, bias=True)\n",
       "  (linear2): Linear(in_features=13, out_features=8, bias=True)\n",
       "  (output): Linear(in_features=8, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将整个网络转移到cpu上来运行\n",
    "net.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6790050e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=20, out_features=13, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       requires_grad=True)\n",
      "Linear(in_features=13, out_features=8, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       requires_grad=True)\n",
      "Linear(in_features=8, out_features=3, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]], requires_grad=True)\n",
      "Model(\n",
      "  (linear1): Linear(in_features=20, out_features=13, bias=True)\n",
      "  (linear2): Linear(in_features=13, out_features=8, bias=True)\n",
      "  (output): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (linear1): Linear(in_features=20, out_features=13, bias=True)\n",
       "  (linear2): Linear(in_features=13, out_features=8, bias=True)\n",
       "  (output): Linear(in_features=8, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net.apply()：对神经网络中所有的层，int函数中所有的对象都执行同样的操作\n",
    "\n",
    "def initial_0(m):\n",
    "    print(m)\n",
    "    if type(m) == nn.Linear:\n",
    "        m.weight.data.fill_(0)\n",
    "        print(m.weight)\n",
    "        \n",
    "net.apply(initial_0) # 参数为函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec3fa1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 1.3508e-01,  1.5439e-01, -1.9350e-01, -6.8777e-02,  1.3787e-01,\n",
      "        -1.8474e-01,  1.2763e-01,  1.8031e-01,  9.5152e-02, -1.2660e-01,\n",
      "         1.4317e-01, -1.4945e-01,  3.4258e-05], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0900, -0.0597,  0.0268, -0.0173,  0.0065,  0.0228, -0.1408,  0.1188],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0156, -0.0730, -0.2637], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# net.parameters()包含所有参数的迭代器\n",
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3.9",
   "language": "python",
   "name": "pytorch3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
