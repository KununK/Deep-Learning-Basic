{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3830d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms # 处理数据模块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553c9f45",
   "metadata": {},
   "source": [
    "# 数据准备 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131f11cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: E:/jupyter/Study/caicai/5_神经网络的学习\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24c13d861c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 实例化数据\n",
    "mnist = torchvision.datasets.FashionMNIST(root=\"E:/jupyter/Study/caicai/5_神经网络的学习\" # 计算机上某个目录路径\n",
    "                                          ,download = False # 是否允许下载\n",
    "                                          ,train = True # 是否是训练集数据\n",
    "                                          ,transform = transforms.ToTensor() #对数据集进行统一处理\n",
    "                                         )\n",
    "mnist\n",
    "# 标签\n",
    "mnist.targets.unique()\n",
    "# 标签编码对应真正的类别\n",
    "mnist.classes\n",
    "\n",
    "# 打印数据集\n",
    "mnist[10][0].shape\n",
    "plt.imshow(mnist[10][0].view(28,28).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b0bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定数据，确定超参数\n",
    "lr = 0.15\n",
    "gamma = 0.2\n",
    "epochs = 10\n",
    "bs = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aec9904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# 切分小批量\n",
    "batchdata = DataLoader(mnist\n",
    "                      ,batch_size = bs\n",
    "                      ,shuffle = True)\n",
    "\n",
    "# 查看切分后的shape\n",
    "for x,y in batchdata:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ec541d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输入\n",
    "input_ = mnist.data[0].numel()# 拉平二维图像\n",
    "# 输出\n",
    "output_ = len(mnist.targets.unique()) \n",
    "input_\n",
    "output_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c35ee6e",
   "metadata": {},
   "source": [
    "# 构建模型 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931d1fad",
   "metadata": {},
   "source": [
    "## 定义网络架构 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d25eca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义神经网络的架构\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,in_features,out_features):\n",
    "        super().__init__()\n",
    "        self.normalize = nn.BatchNorm2d(num_features=1)\n",
    "        self.linear1 = nn.Linear(in_features,128,bias=False)\n",
    "        self.output = nn.Linear(128,out_features,bias=False)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.normalize(x)\n",
    "        x = x.view(-1,28*28)\n",
    "        sigma1 = torch.relu(self.linear1(x))\n",
    "        sigma2 = F.log_softmax(self.output(sigma1),dim=1)\n",
    "        return sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ea61187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models as m\n",
    "from torchinfo import summary\n",
    "\n",
    "vgg16_bn_ = m.vgg16_bn()\n",
    "resnet18_ = m.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5838cc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18_\n",
    "#resnet18_.layer3[0].conv1 = nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "#resnet18_.layer3[0].downsample[0] = nn.Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#resnet18_.layer3[1].conv2 = nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b1f7449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyNet1                                   [10, 10]                  --\n",
       "├─Sequential: 1-1                        [10, 64, 32, 32]          --\n",
       "│    └─Conv2d: 2-1                       [10, 64, 32, 32]          640\n",
       "│    └─BatchNorm2d: 2-2                  [10, 64, 32, 32]          128\n",
       "│    └─ReLU: 2-3                         [10, 64, 32, 32]          --\n",
       "├─Sequential: 1-2                        [10, 128, 16, 16]         --\n",
       "│    └─Conv2d: 2-4                       [10, 128, 32, 32]         73,856\n",
       "│    └─BatchNorm2d: 2-5                  [10, 128, 32, 32]         256\n",
       "│    └─ReLU: 2-6                         [10, 128, 32, 32]         --\n",
       "│    └─Conv2d: 2-7                       [10, 128, 32, 32]         147,584\n",
       "│    └─BatchNorm2d: 2-8                  [10, 128, 32, 32]         256\n",
       "│    └─ReLU: 2-9                         [10, 128, 32, 32]         --\n",
       "│    └─MaxPool2d: 2-10                   [10, 128, 16, 16]         --\n",
       "├─Sequential: 1-3                        [10, 256, 8, 8]           --\n",
       "│    └─BasicBlock: 2-11                  [10, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-1                  [10, 256, 8, 8]           294,912\n",
       "│    │    └─BatchNorm2d: 3-2             [10, 256, 8, 8]           512\n",
       "│    │    └─ReLU: 3-3                    [10, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-4                  [10, 256, 8, 8]           589,824\n",
       "│    │    └─BatchNorm2d: 3-5             [10, 256, 8, 8]           512\n",
       "│    │    └─Sequential: 3-6              [10, 256, 8, 8]           33,280\n",
       "│    │    └─ReLU: 3-7                    [10, 256, 8, 8]           --\n",
       "│    └─BasicBlock: 2-12                  [10, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-8                  [10, 256, 8, 8]           589,824\n",
       "│    │    └─BatchNorm2d: 3-9             [10, 256, 8, 8]           512\n",
       "│    │    └─ReLU: 3-10                   [10, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-11                 [10, 256, 8, 8]           589,824\n",
       "│    │    └─BatchNorm2d: 3-12            [10, 256, 8, 8]           512\n",
       "│    │    └─ReLU: 3-13                   [10, 256, 8, 8]           --\n",
       "├─AdaptiveAvgPool2d: 1-4                 [10, 256, 1, 1]           --\n",
       "├─Linear: 1-5                            [10, 10]                  2,570\n",
       "==========================================================================================\n",
       "Total params: 2,325,002\n",
       "Trainable params: 2,325,002\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 3.62\n",
       "==========================================================================================\n",
       "Input size (MB): 0.04\n",
       "Forward/backward pass size (MB): 65.54\n",
       "Params size (MB): 9.30\n",
       "Estimated Total Size (MB): 74.88\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_bn_ = m.vgg16_bn()\n",
    "resnet18_ = m.resnet18()\n",
    "class MyNet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1,64,kernel_size=3,stride=1,padding=1)\n",
    "                                   ,nn.BatchNorm2d(64)\n",
    "                                   ,nn.ReLU(inplace=True)\n",
    "                                  )\n",
    "        self.block2 = vgg16_bn_.features[7:14]\n",
    "        self.block3 = resnet18_.layer3\n",
    "        self.avgpool = resnet18_.avgpool #-> 1x1\n",
    "        self.fc = nn.Linear(in_features=256, out_features=10, bias=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.block3(self.block2(x))\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0],256)\n",
    "        x = F.log_softmax(self.fc(x),dim=1)\n",
    "        return x\n",
    "\n",
    "data = torch.ones(10,1,32,32)\n",
    "summary(MyNet1(),input_size=(10,1,32,32),depth=3,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c52ae6e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m     24\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[43msummary\u001b[49m(MyNet2(),input_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m),depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'summary' is not defined"
     ]
    }
   ],
   "source": [
    "vgg16_bn_ = m.vgg16_bn()\n",
    "resnet18_ = m.resnet18()\n",
    "class MyNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1,64,kernel_size=3,stride=1,padding=1)\n",
    "                                   ,nn.BatchNorm2d(64)\n",
    "                                   ,nn.ReLU(inplace=True)\n",
    "                                  )\n",
    "        self.block2 = vgg16_bn_.features[7:14]\n",
    "        self.block3 = resnet18_.layer2[1]\n",
    "        self.block4 = resnet18_.layer3[0]\n",
    "        self.avgpool = resnet18_.avgpool #-> 1x1\n",
    "        self.fc = nn.Linear(in_features=256, out_features=10, bias=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.block4(self.block3(self.block2(x)))\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0],256)\n",
    "        x = F.log_softmax(self.fc(x),dim=1)\n",
    "        return x\n",
    "\n",
    "data = torch.ones(10,1,32,32)\n",
    "summary(MyNet2(),input_size=(10,1,32,32),depth=3,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f58eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self,in_,out_=10,**kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_,out_,**kwargs)\n",
    "                                  ,nn.BatchNorm2d(out_)\n",
    "                                  ,nn.ReLU(inplace=True)\n",
    "                                 )\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "class MyNet3(nn.Module):\n",
    "    def __init__(self,in_channels=1,out_features=10):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(BasicConv2d(in_ = in_channels,out_=32,kernel_size=5,padding=2)\n",
    "                                    ,BasicConv2d(32,32,kernel_size=5,padding=2)\n",
    "                                    ,nn.MaxPool2d(2)\n",
    "                                    ,nn.Dropout2d(0.25))\n",
    "        self.block2 = nn.Sequential(BasicConv2d(32,64,kernel_size=3,padding=1)\n",
    "                                   ,BasicConv2d(64,64,kernel_size=3,padding=1)\n",
    "                                   ,BasicConv2d(64,64,kernel_size=3,padding=1)\n",
    "                                   ,nn.MaxPool2d(2)\n",
    "                                   ,nn.Dropout2d(0.25))\n",
    "        \n",
    "        self.classifier_ = nn.Sequential(\n",
    "            nn.Linear(64*7*7,256)\n",
    "            ,nn.BatchNorm1d(256) #此时数据已是二维，因此需要BatchNorm1d\n",
    "            ,nn.ReLU(inplace=True)\n",
    "            ,nn.Linear(256,out_features)\n",
    "            ,nn.LogSoftmax(1)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.block2(self.block1(x))\n",
    "        x = x.view(-1, 64*7*7)\n",
    "        output = self.classifier_(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b99604",
   "metadata": {},
   "source": [
    "## 定义训练过程 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f244ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个训练函数\n",
    "def fit_(net,batchdata,lr=0.01,epochs=5,gamma=0):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # 将模型移到GPU上\n",
    "    net.to(device)\n",
    "\n",
    "    # 定义损失函数\n",
    "    criterion = nn.NLLLoss()\n",
    "    # 定义优化算法\n",
    "    #opt = optim.SGD(net.parameters(),lr=lr,momentum=gamma)\n",
    "    opt = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    # correct和samples可以没有，为了求解准确率定义的\n",
    "    # 预测正确的样本数量\n",
    "    correct = 0\n",
    "    # 模型训练过的样本数量\n",
    "    samples = 0\n",
    "    \n",
    "    for epoch in range(epochs):# 全数据被训练几次\n",
    "        # enumerate 给元素加索引\n",
    "        for batch_idx,(x,y) in enumerate(batchdata):\n",
    "            x, y = x.to(device), y.to(device)  # 将数据移到GPU上\n",
    "            \n",
    "            y = y.view(x.shape[0]) # 多分类将label将为一维防止报错\n",
    "            # 向前传播\n",
    "            sigma = net.forward(x) \n",
    "            # 计算损失函数值\n",
    "            loss = criterion(sigma,y)\n",
    "            # 反向传播 - 得到梯度\n",
    "            loss.backward()\n",
    "            # 更新权重和动量\n",
    "            opt.step()# 更新权重w, 更新动量v\n",
    "            # 清空梯度\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            # 求解准确率\n",
    "            yhat = torch.max(sigma,1)[1]\n",
    "            correct += torch.sum(yhat == y)\n",
    "\n",
    "            # 每次训练一个batch，模型训练过的样本数量加x.shape[0]\n",
    "            samples += x.shape[0]\n",
    "        \n",
    "            if (batch_idx+1)%125 == 0 or batch_idx == len(batchdata)-1:\n",
    "                print(f\"Epoch{epoch+1}:[{samples}/{epochs*len(batchdata.dataset)}({100*samples/(epochs*len(batchdata.dataset)):.2f})%],Loss:{loss.data.item():.2f},Accuracy:{100*correct/samples:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4124ac09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29a16b2bb50>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1:[16000/600000(2.67)%],Loss:0.55,Accuracy:74.66%\n",
      "Epoch1:[32000/600000(5.33)%],Loss:0.46,Accuracy:78.55%\n",
      "Epoch1:[48000/600000(8.00)%],Loss:0.37,Accuracy:80.33%\n",
      "Epoch1:[60000/600000(10.00)%],Loss:0.38,Accuracy:81.15%\n",
      "Epoch2:[76000/600000(12.67)%],Loss:0.47,Accuracy:82.19%\n",
      "Epoch2:[92000/600000(15.33)%],Loss:0.31,Accuracy:82.91%\n",
      "Epoch2:[108000/600000(18.00)%],Loss:0.35,Accuracy:83.38%\n",
      "Epoch2:[120000/600000(20.00)%],Loss:0.39,Accuracy:83.75%\n",
      "Epoch3:[136000/600000(22.67)%],Loss:0.34,Accuracy:84.19%\n",
      "Epoch3:[152000/600000(25.33)%],Loss:0.34,Accuracy:84.62%\n",
      "Epoch3:[168000/600000(28.00)%],Loss:0.42,Accuracy:84.95%\n",
      "Epoch3:[180000/600000(30.00)%],Loss:0.30,Accuracy:85.16%\n",
      "Epoch4:[196000/600000(32.67)%],Loss:0.35,Accuracy:85.47%\n",
      "Epoch4:[212000/600000(35.33)%],Loss:0.29,Accuracy:85.71%\n",
      "Epoch4:[228000/600000(38.00)%],Loss:0.30,Accuracy:85.91%\n",
      "Epoch4:[240000/600000(40.00)%],Loss:0.29,Accuracy:86.05%\n",
      "Epoch5:[256000/600000(42.67)%],Loss:0.36,Accuracy:86.27%\n",
      "Epoch5:[272000/600000(45.33)%],Loss:0.14,Accuracy:86.45%\n",
      "Epoch5:[288000/600000(48.00)%],Loss:0.18,Accuracy:86.60%\n",
      "Epoch5:[300000/600000(50.00)%],Loss:0.22,Accuracy:86.71%\n",
      "Epoch6:[316000/600000(52.67)%],Loss:0.20,Accuracy:86.89%\n",
      "Epoch6:[332000/600000(55.33)%],Loss:0.30,Accuracy:87.03%\n",
      "Epoch6:[348000/600000(58.00)%],Loss:0.30,Accuracy:87.15%\n",
      "Epoch6:[360000/600000(60.00)%],Loss:0.27,Accuracy:87.24%\n",
      "Epoch7:[376000/600000(62.67)%],Loss:0.23,Accuracy:87.38%\n",
      "Epoch7:[392000/600000(65.33)%],Loss:0.26,Accuracy:87.50%\n",
      "Epoch7:[408000/600000(68.00)%],Loss:0.21,Accuracy:87.60%\n",
      "Epoch7:[420000/600000(70.00)%],Loss:0.25,Accuracy:87.68%\n",
      "Epoch8:[436000/600000(72.67)%],Loss:0.22,Accuracy:87.81%\n",
      "Epoch8:[452000/600000(75.33)%],Loss:0.28,Accuracy:87.90%\n",
      "Epoch8:[468000/600000(78.00)%],Loss:0.21,Accuracy:88.00%\n",
      "Epoch8:[480000/600000(80.00)%],Loss:0.33,Accuracy:88.07%\n",
      "Epoch9:[496000/600000(82.67)%],Loss:0.22,Accuracy:88.17%\n",
      "Epoch9:[512000/600000(85.33)%],Loss:0.35,Accuracy:88.26%\n",
      "Epoch9:[528000/600000(88.00)%],Loss:0.25,Accuracy:88.34%\n",
      "Epoch9:[540000/600000(90.00)%],Loss:0.40,Accuracy:88.41%\n",
      "Epoch10:[556000/600000(92.67)%],Loss:0.24,Accuracy:88.49%\n",
      "Epoch10:[572000/600000(95.33)%],Loss:0.23,Accuracy:88.58%\n",
      "Epoch10:[588000/600000(98.00)%],Loss:0.16,Accuracy:88.66%\n",
      "Epoch10:[600000/600000(100.00)%],Loss:0.27,Accuracy:88.72%\n"
     ]
    }
   ],
   "source": [
    "# 模型训练与评估\n",
    "torch.manual_seed(420)\n",
    "net = Model(in_features=input_,out_features=output_)\n",
    "fit_(net,batchdata,lr=lr,epochs=epochs,gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8b779a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29a16b2bb50>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1:[16000/600000(2.67)%],Loss:0.41,Accuracy:69.83%\n",
      "Epoch1:[32000/600000(5.33)%],Loss:0.60,Accuracy:76.70%\n",
      "Epoch1:[48000/600000(8.00)%],Loss:0.36,Accuracy:79.71%\n",
      "Epoch1:[60000/600000(10.00)%],Loss:0.36,Accuracy:81.20%\n",
      "Epoch2:[76000/600000(12.67)%],Loss:0.25,Accuracy:82.79%\n",
      "Epoch2:[92000/600000(15.33)%],Loss:0.25,Accuracy:84.07%\n",
      "Epoch2:[108000/600000(18.00)%],Loss:0.22,Accuracy:84.94%\n",
      "Epoch2:[120000/600000(20.00)%],Loss:0.22,Accuracy:85.47%\n",
      "Epoch3:[136000/600000(22.67)%],Loss:0.17,Accuracy:86.20%\n",
      "Epoch3:[152000/600000(25.33)%],Loss:0.30,Accuracy:86.72%\n",
      "Epoch3:[168000/600000(28.00)%],Loss:0.42,Accuracy:87.22%\n",
      "Epoch3:[180000/600000(30.00)%],Loss:0.20,Accuracy:87.54%\n",
      "Epoch4:[196000/600000(32.67)%],Loss:0.18,Accuracy:87.99%\n",
      "Epoch4:[212000/600000(35.33)%],Loss:0.20,Accuracy:88.35%\n",
      "Epoch4:[228000/600000(38.00)%],Loss:0.19,Accuracy:88.69%\n",
      "Epoch4:[240000/600000(40.00)%],Loss:0.25,Accuracy:88.91%\n",
      "Epoch5:[256000/600000(42.67)%],Loss:0.16,Accuracy:89.24%\n",
      "Epoch5:[272000/600000(45.33)%],Loss:0.22,Accuracy:89.53%\n",
      "Epoch5:[288000/600000(48.00)%],Loss:0.23,Accuracy:89.78%\n",
      "Epoch5:[300000/600000(50.00)%],Loss:0.14,Accuracy:89.95%\n",
      "Epoch6:[316000/600000(52.67)%],Loss:0.10,Accuracy:90.22%\n",
      "Epoch6:[332000/600000(55.33)%],Loss:0.19,Accuracy:90.46%\n",
      "Epoch6:[348000/600000(58.00)%],Loss:0.09,Accuracy:90.67%\n",
      "Epoch6:[360000/600000(60.00)%],Loss:0.12,Accuracy:90.81%\n",
      "Epoch7:[376000/600000(62.67)%],Loss:0.08,Accuracy:91.03%\n",
      "Epoch7:[392000/600000(65.33)%],Loss:0.06,Accuracy:91.25%\n",
      "Epoch7:[408000/600000(68.00)%],Loss:0.14,Accuracy:91.42%\n",
      "Epoch7:[420000/600000(70.00)%],Loss:0.15,Accuracy:91.54%\n",
      "Epoch8:[436000/600000(72.67)%],Loss:0.04,Accuracy:91.75%\n",
      "Epoch8:[452000/600000(75.33)%],Loss:0.12,Accuracy:91.93%\n",
      "Epoch8:[468000/600000(78.00)%],Loss:0.15,Accuracy:92.08%\n",
      "Epoch8:[480000/600000(80.00)%],Loss:0.11,Accuracy:92.19%\n",
      "Epoch9:[496000/600000(82.67)%],Loss:0.05,Accuracy:92.37%\n",
      "Epoch9:[512000/600000(85.33)%],Loss:0.08,Accuracy:92.53%\n",
      "Epoch9:[528000/600000(88.00)%],Loss:0.05,Accuracy:92.67%\n",
      "Epoch9:[540000/600000(90.00)%],Loss:0.04,Accuracy:92.76%\n",
      "Epoch10:[556000/600000(92.67)%],Loss:0.04,Accuracy:92.92%\n",
      "Epoch10:[572000/600000(95.33)%],Loss:0.03,Accuracy:93.07%\n",
      "Epoch10:[588000/600000(98.00)%],Loss:0.13,Accuracy:93.20%\n",
      "Epoch10:[600000/600000(100.00)%],Loss:0.14,Accuracy:93.29%\n"
     ]
    }
   ],
   "source": [
    "# 模型训练与评估\n",
    "torch.manual_seed(420)\n",
    "net1 = MyNet1()\n",
    "fit_(net1,batchdata,lr=lr,epochs=epochs,gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "401298e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29a16b2bb50>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1:[16000/600000(2.67)%],Loss:0.48,Accuracy:69.69%\n",
      "Epoch1:[32000/600000(5.33)%],Loss:0.65,Accuracy:76.19%\n",
      "Epoch1:[48000/600000(8.00)%],Loss:0.35,Accuracy:79.27%\n",
      "Epoch1:[60000/600000(10.00)%],Loss:0.39,Accuracy:80.81%\n",
      "Epoch2:[76000/600000(12.67)%],Loss:0.26,Accuracy:82.38%\n",
      "Epoch2:[92000/600000(15.33)%],Loss:0.26,Accuracy:83.63%\n",
      "Epoch2:[108000/600000(18.00)%],Loss:0.21,Accuracy:84.52%\n",
      "Epoch2:[120000/600000(20.00)%],Loss:0.22,Accuracy:85.07%\n",
      "Epoch3:[136000/600000(22.67)%],Loss:0.19,Accuracy:85.77%\n",
      "Epoch3:[152000/600000(25.33)%],Loss:0.29,Accuracy:86.31%\n",
      "Epoch3:[168000/600000(28.00)%],Loss:0.51,Accuracy:86.81%\n",
      "Epoch3:[180000/600000(30.00)%],Loss:0.22,Accuracy:87.13%\n",
      "Epoch4:[196000/600000(32.67)%],Loss:0.24,Accuracy:87.55%\n",
      "Epoch4:[212000/600000(35.33)%],Loss:0.29,Accuracy:87.89%\n",
      "Epoch4:[228000/600000(38.00)%],Loss:0.25,Accuracy:88.24%\n",
      "Epoch4:[240000/600000(40.00)%],Loss:0.26,Accuracy:88.46%\n",
      "Epoch5:[256000/600000(42.67)%],Loss:0.17,Accuracy:88.77%\n",
      "Epoch5:[272000/600000(45.33)%],Loss:0.22,Accuracy:89.04%\n",
      "Epoch5:[288000/600000(48.00)%],Loss:0.25,Accuracy:89.29%\n",
      "Epoch5:[300000/600000(50.00)%],Loss:0.18,Accuracy:89.44%\n",
      "Epoch6:[316000/600000(52.67)%],Loss:0.15,Accuracy:89.68%\n",
      "Epoch6:[332000/600000(55.33)%],Loss:0.20,Accuracy:89.90%\n",
      "Epoch6:[348000/600000(58.00)%],Loss:0.11,Accuracy:90.10%\n",
      "Epoch6:[360000/600000(60.00)%],Loss:0.17,Accuracy:90.24%\n",
      "Epoch7:[376000/600000(62.67)%],Loss:0.11,Accuracy:90.45%\n",
      "Epoch7:[392000/600000(65.33)%],Loss:0.08,Accuracy:90.64%\n",
      "Epoch7:[408000/600000(68.00)%],Loss:0.19,Accuracy:90.80%\n",
      "Epoch7:[420000/600000(70.00)%],Loss:0.16,Accuracy:90.92%\n",
      "Epoch8:[436000/600000(72.67)%],Loss:0.07,Accuracy:91.11%\n",
      "Epoch8:[452000/600000(75.33)%],Loss:0.17,Accuracy:91.27%\n",
      "Epoch8:[468000/600000(78.00)%],Loss:0.18,Accuracy:91.41%\n",
      "Epoch8:[480000/600000(80.00)%],Loss:0.12,Accuracy:91.51%\n",
      "Epoch9:[496000/600000(82.67)%],Loss:0.13,Accuracy:91.68%\n",
      "Epoch9:[512000/600000(85.33)%],Loss:0.08,Accuracy:91.83%\n",
      "Epoch9:[528000/600000(88.00)%],Loss:0.09,Accuracy:91.96%\n",
      "Epoch9:[540000/600000(90.00)%],Loss:0.11,Accuracy:92.05%\n",
      "Epoch10:[556000/600000(92.67)%],Loss:0.05,Accuracy:92.21%\n",
      "Epoch10:[572000/600000(95.33)%],Loss:0.05,Accuracy:92.35%\n",
      "Epoch10:[588000/600000(98.00)%],Loss:0.17,Accuracy:92.47%\n",
      "Epoch10:[600000/600000(100.00)%],Loss:0.14,Accuracy:92.55%\n"
     ]
    }
   ],
   "source": [
    "# 模型训练与评估\n",
    "torch.manual_seed(420)\n",
    "net2 = MyNet2()\n",
    "fit_(net2,batchdata,lr=lr,epochs=epochs,gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfc508ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24c04f7eb50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1:[16000/600000(2.67)%],Loss:0.42,Accuracy:80.24%\n",
      "Epoch1:[32000/600000(5.33)%],Loss:0.32,Accuracy:83.43%\n",
      "Epoch1:[48000/600000(8.00)%],Loss:0.24,Accuracy:85.14%\n",
      "Epoch1:[60000/600000(10.00)%],Loss:0.39,Accuracy:85.82%\n",
      "Epoch2:[76000/600000(12.67)%],Loss:0.24,Accuracy:86.70%\n",
      "Epoch2:[92000/600000(15.33)%],Loss:0.26,Accuracy:87.28%\n",
      "Epoch2:[108000/600000(18.00)%],Loss:0.22,Accuracy:87.78%\n",
      "Epoch2:[120000/600000(20.00)%],Loss:0.16,Accuracy:88.11%\n",
      "Epoch3:[136000/600000(22.67)%],Loss:0.22,Accuracy:88.48%\n",
      "Epoch3:[152000/600000(25.33)%],Loss:0.24,Accuracy:88.81%\n",
      "Epoch3:[168000/600000(28.00)%],Loss:0.20,Accuracy:89.06%\n",
      "Epoch3:[180000/600000(30.00)%],Loss:0.22,Accuracy:89.27%\n",
      "Epoch4:[196000/600000(32.67)%],Loss:0.28,Accuracy:89.52%\n",
      "Epoch4:[212000/600000(35.33)%],Loss:0.26,Accuracy:89.75%\n",
      "Epoch4:[228000/600000(38.00)%],Loss:0.26,Accuracy:89.93%\n",
      "Epoch4:[240000/600000(40.00)%],Loss:0.15,Accuracy:90.07%\n",
      "Epoch5:[256000/600000(42.67)%],Loss:0.22,Accuracy:90.27%\n",
      "Epoch5:[272000/600000(45.33)%],Loss:0.19,Accuracy:90.43%\n",
      "Epoch5:[288000/600000(48.00)%],Loss:0.21,Accuracy:90.56%\n",
      "Epoch5:[300000/600000(50.00)%],Loss:0.18,Accuracy:90.67%\n",
      "Epoch6:[316000/600000(52.67)%],Loss:0.23,Accuracy:90.85%\n",
      "Epoch6:[332000/600000(55.33)%],Loss:0.23,Accuracy:90.99%\n",
      "Epoch6:[348000/600000(58.00)%],Loss:0.19,Accuracy:91.11%\n",
      "Epoch6:[360000/600000(60.00)%],Loss:0.21,Accuracy:91.19%\n",
      "Epoch7:[376000/600000(62.67)%],Loss:0.16,Accuracy:91.32%\n",
      "Epoch7:[392000/600000(65.33)%],Loss:0.26,Accuracy:91.44%\n",
      "Epoch7:[408000/600000(68.00)%],Loss:0.12,Accuracy:91.56%\n",
      "Epoch7:[420000/600000(70.00)%],Loss:0.11,Accuracy:91.63%\n",
      "Epoch8:[436000/600000(72.67)%],Loss:0.15,Accuracy:91.74%\n",
      "Epoch8:[452000/600000(75.33)%],Loss:0.09,Accuracy:91.83%\n",
      "Epoch8:[468000/600000(78.00)%],Loss:0.12,Accuracy:91.92%\n",
      "Epoch8:[480000/600000(80.00)%],Loss:0.24,Accuracy:91.98%\n",
      "Epoch9:[496000/600000(82.67)%],Loss:0.12,Accuracy:92.09%\n",
      "Epoch9:[512000/600000(85.33)%],Loss:0.13,Accuracy:92.17%\n",
      "Epoch9:[528000/600000(88.00)%],Loss:0.09,Accuracy:92.27%\n",
      "Epoch9:[540000/600000(90.00)%],Loss:0.08,Accuracy:92.32%\n",
      "Epoch10:[556000/600000(92.67)%],Loss:0.11,Accuracy:92.42%\n",
      "Epoch10:[572000/600000(95.33)%],Loss:0.10,Accuracy:92.50%\n",
      "Epoch10:[588000/600000(98.00)%],Loss:0.12,Accuracy:92.58%\n",
      "Epoch10:[600000/600000(100.00)%],Loss:0.14,Accuracy:92.64%\n"
     ]
    }
   ],
   "source": [
    "# 模型训练与评估\n",
    "torch.manual_seed(420)\n",
    "net3 = MyNet3(out_features=output_)\n",
    "fit_(net3,batchdata,lr=lr,epochs=epochs,gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a5786b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24c04f7eb50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1:[16000/600000(2.67)%],Loss:0.35,Accuracy:80.96%\n",
      "Epoch1:[32000/600000(5.33)%],Loss:0.28,Accuracy:84.16%\n",
      "Epoch1:[48000/600000(8.00)%],Loss:0.22,Accuracy:85.68%\n",
      "Epoch1:[60000/600000(10.00)%],Loss:0.26,Accuracy:86.38%\n",
      "Epoch2:[76000/600000(12.67)%],Loss:0.24,Accuracy:87.26%\n",
      "Epoch2:[92000/600000(15.33)%],Loss:0.22,Accuracy:87.74%\n",
      "Epoch2:[108000/600000(18.00)%],Loss:0.25,Accuracy:88.15%\n",
      "Epoch2:[120000/600000(20.00)%],Loss:0.17,Accuracy:88.49%\n",
      "Epoch3:[136000/600000(22.67)%],Loss:0.21,Accuracy:88.88%\n",
      "Epoch3:[152000/600000(25.33)%],Loss:0.21,Accuracy:89.19%\n",
      "Epoch3:[168000/600000(28.00)%],Loss:0.21,Accuracy:89.44%\n",
      "Epoch3:[180000/600000(30.00)%],Loss:0.17,Accuracy:89.64%\n",
      "Epoch4:[196000/600000(32.67)%],Loss:0.23,Accuracy:89.91%\n",
      "Epoch4:[212000/600000(35.33)%],Loss:0.20,Accuracy:90.12%\n",
      "Epoch4:[228000/600000(38.00)%],Loss:0.25,Accuracy:90.29%\n",
      "Epoch4:[240000/600000(40.00)%],Loss:0.15,Accuracy:90.41%\n",
      "Epoch5:[256000/600000(42.67)%],Loss:0.22,Accuracy:90.61%\n",
      "Epoch5:[272000/600000(45.33)%],Loss:0.18,Accuracy:90.76%\n",
      "Epoch5:[288000/600000(48.00)%],Loss:0.18,Accuracy:90.90%\n",
      "Epoch5:[300000/600000(50.00)%],Loss:0.13,Accuracy:91.01%\n",
      "Epoch6:[316000/600000(52.67)%],Loss:0.24,Accuracy:91.18%\n",
      "Epoch6:[332000/600000(55.33)%],Loss:0.21,Accuracy:91.33%\n",
      "Epoch6:[348000/600000(58.00)%],Loss:0.15,Accuracy:91.45%\n",
      "Epoch6:[360000/600000(60.00)%],Loss:0.18,Accuracy:91.51%\n",
      "Epoch7:[376000/600000(62.67)%],Loss:0.18,Accuracy:91.65%\n",
      "Epoch7:[392000/600000(65.33)%],Loss:0.26,Accuracy:91.77%\n",
      "Epoch7:[408000/600000(68.00)%],Loss:0.11,Accuracy:91.88%\n",
      "Epoch7:[420000/600000(70.00)%],Loss:0.12,Accuracy:91.95%\n",
      "Epoch8:[436000/600000(72.67)%],Loss:0.13,Accuracy:92.08%\n",
      "Epoch8:[452000/600000(75.33)%],Loss:0.08,Accuracy:92.19%\n",
      "Epoch8:[468000/600000(78.00)%],Loss:0.10,Accuracy:92.28%\n",
      "Epoch8:[480000/600000(80.00)%],Loss:0.18,Accuracy:92.35%\n",
      "Epoch9:[496000/600000(82.67)%],Loss:0.08,Accuracy:92.45%\n",
      "Epoch9:[512000/600000(85.33)%],Loss:0.17,Accuracy:92.54%\n",
      "Epoch9:[528000/600000(88.00)%],Loss:0.06,Accuracy:92.63%\n",
      "Epoch9:[540000/600000(90.00)%],Loss:0.08,Accuracy:92.69%\n",
      "Epoch10:[556000/600000(92.67)%],Loss:0.13,Accuracy:92.79%\n",
      "Epoch10:[572000/600000(95.33)%],Loss:0.11,Accuracy:92.88%\n",
      "Epoch10:[588000/600000(98.00)%],Loss:0.12,Accuracy:92.96%\n",
      "Epoch10:[600000/600000(100.00)%],Loss:0.11,Accuracy:93.02%\n"
     ]
    }
   ],
   "source": [
    "# 模型训练与评估\n",
    "torch.manual_seed(420)\n",
    "net3 = MyNet3(out_features=output_)\n",
    "fit_(net3,batchdata,lr=0.001,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb91d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c43e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\app2\\Anaconda\\envs\\pytorch3.9\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "f:\\app2\\Anaconda\\envs\\pytorch3.9\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "res18pt = m.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6787e1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0104, -0.0061, -0.0018,  0.0748,  0.0566,  0.0171, -0.0127],\n",
       "        [ 0.0111,  0.0095, -0.1099, -0.2805, -0.2712, -0.1291,  0.0037],\n",
       "        [-0.0069,  0.0591,  0.2955,  0.5872,  0.5197,  0.2563,  0.0636],\n",
       "        [ 0.0305, -0.0670, -0.2984, -0.4387, -0.2709, -0.0006,  0.0576],\n",
       "        [-0.0275,  0.0160,  0.0726, -0.0541, -0.3328, -0.4206, -0.2578],\n",
       "        [ 0.0306,  0.0410,  0.0628,  0.2390,  0.4138,  0.3936,  0.1661],\n",
       "        [-0.0137, -0.0037, -0.0241, -0.0659, -0.1507, -0.0822, -0.0058]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res18pt = m.resnet18(weights='DEFAULT')\n",
    "res18pt.conv1.weight[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f80131d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0104, -0.0061, -0.0018,  0.0748,  0.0566,  0.0171, -0.0127],\n",
       "        [ 0.0111,  0.0095, -0.1099, -0.2805, -0.2712, -0.1291,  0.0037],\n",
       "        [-0.0069,  0.0591,  0.2955,  0.5872,  0.5197,  0.2563,  0.0636],\n",
       "        [ 0.0305, -0.0670, -0.2984, -0.4387, -0.2709, -0.0006,  0.0576],\n",
       "        [-0.0275,  0.0160,  0.0726, -0.0541, -0.3328, -0.4206, -0.2578],\n",
       "        [ 0.0306,  0.0410,  0.0628,  0.2390,  0.4138,  0.3936,  0.1661],\n",
       "        [-0.0137, -0.0037, -0.0241, -0.0659, -0.1507, -0.0822, -0.0058]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res18pt = m.resnet18(weights='IMAGENET1K_V1')\n",
    "res18pt.conv1.weight[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4b466e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1997e-02,  3.2418e-02,  8.8922e-03,  1.7633e-02, -4.0451e-03,\n",
       "         -4.0831e-02, -1.3448e-02],\n",
       "        [-1.2586e-02,  9.3377e-03, -2.1951e-02,  4.5489e-03, -1.1026e-02,\n",
       "         -3.7333e-03, -1.3121e-02],\n",
       "        [ 2.6318e-05, -1.1540e-02, -5.1314e-03,  4.0690e-02, -2.3519e-02,\n",
       "         -5.5018e-03, -9.5371e-03],\n",
       "        [ 1.5426e-02,  7.0454e-02,  1.7844e-02,  3.8229e-02, -3.8968e-02,\n",
       "          2.6191e-02, -1.9457e-02],\n",
       "        [ 3.7230e-02, -5.7666e-03,  4.0124e-03, -4.5354e-03,  1.0143e-02,\n",
       "         -4.9118e-02, -4.9631e-02],\n",
       "        [ 2.6891e-02,  2.9218e-02,  2.5833e-02, -3.5628e-03,  1.8920e-02,\n",
       "         -8.4390e-03, -3.4539e-03],\n",
       "        [ 3.4206e-02, -4.8687e-02,  2.0985e-03, -4.1109e-02, -6.0052e-03,\n",
       "         -1.3575e-02,  4.3677e-02]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18_.conv1.weight[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f0823c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
